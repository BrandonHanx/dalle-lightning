
gcloud  beta compute tpus create tpu-1 --zone=europe-west4-a --network=lgai-vision-vpc-network --accelerator-type=v3-32 --version=pytorch-1.8 --reserved

gcloud  beta compute tpus create tpu-1 --zone=europe-west4-a --network=lgai-vision-vpc-network --accelerator-type=v2-8 --version=pytorch-1.8 --reserved
    
gcloud compute instances create tpu-test --zone=europe-west4-a --machine-type=n1-standard-16 --image-family=torch-xla --image-project=ml-images --boot-disk-size=200GB --scopes=https://www.googleapis.com/auth/cloud-platform --project=lgai-vision-tpu --network=lgai-vision-vpc-network


python3 -m torch_xla.distributed.xla_dist --tpu=${TPU_NAME} -- python3 home/taehoon.kim/taming-transformers/main.py --base configs/coco_vqgan.yaml -t True


——————————————————————————————

gcloud services enable tpu.googleapis.com

gcloud alpha compute tpus tpu-vm create tpu-vm --zone=europe-west4-a --accelerator-type=v3-8 --version=v2-alpha 


gcloud alpha compute tpus tpu-vm ssh tpu-vm --zone europe-west4-a --project lgai-vision-tpu

export XRT_TPU_CONFIG="localservice;0;localhost:51011"


python3 /home/taehoon.kim/taming-transformers/main.py --base /home/taehoon.kim/taming-transformers/configs/coco_vqgan.yaml -t True --tpu_cores=8 --num_sanity_val_steps=1 --precision=16

python3 -m torch_xla.core.xrt_run_server --port 51011 --restart


-------------------------------

python3 -m torch_xla.core.xrt_run_server --port 51011 --restart

sudo /opt/google-cloud-sdk/bin/gcloud components update

export PROJECT_ID=lgai-vision-tpu
export TPU_NAME=tpu-vm-pod-32
export ZONE=europe-west4-a
export RUNTIME_VERSION=v2-alpha

gcloud alpha compute tpus tpu-vm create ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --accelerator-type v3-32 \
--version ${RUNTIME_VERSION}  --reserved --metadata startup-script='#! /bin/bash
cd /home/taehoon.kim/
gcloud source repos clone vqgan --project=lgai-vision-tpu

cd vqgan

mkdir data
mkdir results

pip3 install -r requirements.txt

mkdir temp

chown taehoon.kim data
chown taehoon.kim results
chown -R taehoon.kim vqgan
chown taehoon.kim temp
EOF'

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID}


export VM_NAME=pod-ctrl-32
export ZONE=europe-west4-a

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} 

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "gcsfuse lgaivision-sbu-eu vqgan/data"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "gcsfuse lgaivision-tpu-results vqgan/results"

gcloud compute --project=lgai-vision-tpu instances create pod-ctrl-32\
  --zone=europe-west4-a  \
  --machine-type=n1-standard-1  \
  --image-family=torch-xla \
  --image-project=ml-images  \
  --boot-disk-size=200GB \
  --scopes=https://www.googleapis.com/auth/cloud-platform


gcloud compute config-ssh
conda activate torch-xla-1.8.1

export TPU_NAME=tpu-vm-pod-32




python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-32 --restart-tpuvm-pod --env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4  -- python3 /home/taehoon.kim/taming-transformers/main.py --base /home/taehoon.kim/taming-transformers/configs/coco_vqgan.yaml -t True --num_sanity_val_steps=0 --tpu_cores=8 --precision=16 --checkpoint_callback=False


----------------------


export PROJECT_ID=lgai-vision-tpu
export TPU_NAME=tpu-vm-pod-256
export ZONE=europe-west4-a
export RUNTIME_VERSION=v2-alpha

gcloud alpha compute tpus tpu-vm create ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --accelerator-type v3-256 \
--version ${RUNTIME_VERSION}  --reserved --metadata startup-script='#! /bin/bash
cd /home/taehoon.kim/
mkdir coco_bucket
gcsfuse lgaivision-coco-eu coco_bucket
mkdir coco
cp coco_bucket/train2017.zip coco/
cd coco
unzip train2017.zip
cd ..
cp -r coco_bucket/taming-transformers/ /home/taehoon.kim/ 
fusermount -u /home/taehoon.kim/coco_bucket/

cd taming-transformers
pip3 install -r requirements.txt
cd ..
mkdir /home/taehoon.kim/temp/
chmod -R 777 /home/taehoon.kim/coco_bucket
chmod -R 777 /home/taehoon.kim/taming-transformers/
chmod -R 777 /home/taehoon.kim/coco
chmod -R 777 /home/taehoon.kim/temp
EOF'


export VM_NAME=pod-ctrl-256
export ZONE=europe-west4-a



gcloud compute --project=lgai-vision-tpu instances create pod-ctrl-256 \
  --zone=europe-west4-a  \
  --machine-type=n1-standard-1  \
  --image-family=torch-xla \
  --image-project=ml-images  \
  --boot-disk-size=200GB \
  --scopes=https://www.googleapis.com/auth/cloud-platform

gcloud compute ssh pod-ctrl-256 --zone=europe-west4-a

gcloud compute config-ssh

conda activate torch-xla-1.8.1

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod --env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4  -- python3 /home/taehoon.kim/taming-transformers/main.py --base /home/taehoon.kim/taming-transformers/configs/coco_vqgan.yaml -t True --num_sanity_val_steps=0 --tpu_cores=8 --precision=16 --checkpoint_callback=False


